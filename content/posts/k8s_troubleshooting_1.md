---
title: "Устранение неполадок модулей и кластера Kubernetes"
date: 2024-04-30T13:18:11+03:00
slug: k8s_troubleshooting
aliases:
  - k8s_troubleshooting
weight: 10010
toc_hide: true
tags:
  - k8s
---

## Три ключевых момента при устранении неполадок K8s

Эффективное устранение неполадок в кластере Kubernetes состоит из трех компонентов:

1. Understanding:

Может быть сложно понять, что произошло, и установить основную причину проблемы в системе Kubernetes. Обычно это состоит из:

- Проверка последних изменений в проблемном кластере, модуле или узле для определения источника проблемы.
- Анализ настроек YAML, репозиториев Github и журналов виртуальных машин или аппаратных компьютеров, содержащих неисправные компоненты.
- Анализ событий и показателей K8, таких как нагрузка на диск, нехватка памяти и использование. В зрелой системе должны быть доступны информационные панели, которые предоставляют важные показатели для кластеров, узлов, модулей и контейнеров во времени.
- Сравнение сопоставимых компонентов, которые ведут себя одинаково, и изучение зависимостей компонентов, чтобы определить, связаны ли они с сбоем.

Для достижения вышеупомянутых целей команды обычно используют следующие технологии:

- Monitoring.
- Observability.
- Live Debugging.
- Logging.

2. Management:

Каждый компонент архитектуры микросервисов часто создается и управляется отдельной командой. Поскольку производственные мероприятия часто включают в себя несколько компонентов, быстрое решение проблем требует координации.

После того, как проблема определена, есть три варианта ее решения:
- Ad hoc solutions(cпециальные решения): создаются командами, работающими над затронутыми компонентами с использованием племенных знаний. Зачастую инженер, спроектировавший компонент, обладает неписаными знаниями о том, как его устранять и устранять.
- Manual runbooks (ручные инструкции): четкий письменный протокол для решения каждого типа проблем. С помощью Runbook каждый член команды может быстро решить проблему.
- Automated runbooks (автоматизированные модули Runbook): автоматизированный модуль Runbook — это автоматизированная процедура, которая запускается автоматически при обнаружении проблемы и может быть реализована в виде сценария, шаблона инфраструктуры как кода (IaC) или оператора Kubernetes. Автоматизировать реакции на все типичные ситуации может быть сложно, но это может быть чрезвычайно полезно с точки зрения сокращения простоев и исключения человеческих ошибок.

3. Prevention:

Успешные команды ставят профилактику выше всего остального. Это позволит сократить время, затрачиваемое на обнаружение и устранение новых проблем с течением времени. Предотвращение производственных проблем с помощью Kubernetes включает в себя следующие шаги:

- После каждого события разрабатываются политики, процедуры и сценарии, обеспечивающие эффективный ремонт.
Выясняем, можно ли автоматизировать реакцию на проблему и если да, то каким образом.
- Определение того, как быстро обнаружить проблему в следующий раз и сделать соответствующие данные доступными, например, путем инструментирования ключевых компонентов.
- Обеспечение того, чтобы проблема была передана соответствующим командам и что эти команды могут эффективно взаимодействовать для ее решения.

## Почему устранение неполадок Kubernetes так сложно?

Kubernetes — сложная система, поэтому проблемы отладки, возникающие в кластере Kubernetes, также могут быть непростыми.

Даже в небольшом локальном кластере Kubernetes диагностика и устранение проблем может оказаться сложной задачей, поскольку они могут возникнуть в одном контейнере, одном или нескольких модулях, контроллере, компоненте плоскости управления или их комбинации.

Эти проблемы усугубляются в условиях крупномасштабного производства из-за отсутствия обзора и большого количества движущихся частей. Командам может потребоваться использовать дополнительные инструменты для диагностики и устранения проблем, которые они обнаруживают после использования различных инструментов для сбора данных, необходимых для устранения неполадок.

Другими словами, если команды не будут тесно сотрудничать и не будут располагать соответствующими инструментами, устранение неполадок Kubernetes может быстро превратиться в катастрофу, привести к потере значительных ресурсов и нанести вред пользователям и работе приложений.

## Устранение неполадок подов Kubernetes

Если у вас возникли проблемы с модулем Kubernetes и вы не смогли обнаружить и быстро устранить ошибку, описанную в приведенной выше части, вот как можно пойти немного дальше. Запуск kubectl define pod [name] — это первый шаг в выявлении проблем с модулем.

### ImagePullBackOff или ErrImagePull

Этот статус указывает на то, что модуль не смог запуститься, поскольку он попытался получить образ контейнера из реестра, но не смог. Модуль не запустится, поскольку он не может создать один или несколько контейнеров, указанных в его манифесте.

Чтобы определить проблему, выполните следующую команду:

```
kubectl get pods
```

Проверьте выходные данные, является ли статус модуля ImagePullBackOff или ErrImagePull.

Это может быть один из следующих вариантов:

**Incorrect image name or tag** (неверное имя или тег изображения): Обычно это происходит из-за того, что имя или тег изображения были ошибочно написаны в манифесте модуля. Используя docker pull, подтвердите правильное имя образа и обновите его в манифесте модуля.

**Authentication failure in the Container Registry** (ошибка аутентификации в реестре контейнеров):
модулю не удалось пройти аутентификацию в реестре для получения образа. Это может быть из-за проблемы с секретными учетными данными или из-за того, что у модуля отсутствует роль RBAC, которая позволяет ему выполнять транзакцию. Прежде чем пытаться выполнить операцию вручную с помощью docker pull , убедитесь, что модуль и узел имеют необходимые права и секреты.

### CreateContainerConfigError

Эта проблема обычно возникает из-за отсутствия Secret или ConfigMap. Секреты — это объекты Kubernetes, которые используются для хранения конфиденциальных данных, таких как учетные данные базы данных. ConfigMaps часто используются для переноса информации о конфигурации, используемой многочисленными модулями, и сохранения данных в виде пар ключ-значение.

Чтобы определить проблему, выполните следующую команду:
```
kubectl get pods
```

Посмотрите выходные данные, является ли статус модуля CreateContainerConfigError .

Чтобы получить подробную информацию об ошибке, выполните приведенную ниже команду и найдите сообщение, указывающее, какой ConfigMap отсутствует:
```
kubectl describe pod <name>
```
Запустите команду, чтобы проверить, присутствует ли ConfigMap в кластере.
```
kubectl get configmap configmap-3
```

Если результат равен нулю, ConfigMap отсутствует и его необходимо создать. Узнайте, как создать ConfigMap.

Запустите get configmap [имя] еще раз, чтобы убедиться, что ConfigMap по-прежнему доступен. Если вы хотите просмотреть содержимое ConfigMap в формате YAML, используйте ключ -o yaml.

Убедившись, что ConfigMap существует, снова запустите kubectl get pods , чтобы убедиться, что модуль находится в рабочем состоянии.

### CrashLoopBackOff

Эта ошибка означает, что pod невозможно запланировать на узле. Это может быть связано с тем, что узлу не хватает ресурсов для работы  pod или с тем, что модуль не смог смонтировать запрошенные тома.

Чтобы определить проблему, выполните следующую команду:
```
kubectl get pods
```
Чтобы получить подробную информацию об ошибке, выполните следующую команду:
```
 kubectl describe pod <name>
```

Результаты помогут вам определить основную причину проблемы. Ниже приведены некоторые из наиболее распространенных причин:

Insufficient resources (недостаточно ресурсов): Если ресурсов узла недостаточно, вы можете вручную исключить pods из узла или масштабировать кластер, чтобы гарантировать доступность большего количества узлов для ваших модулей.

Volume mounting (монтирование тома): Если проблема связана с монтированием тома хранилища, проверьте том, который pod пытается смонтировать, убедитесь, что он точно указан в манифесте pod, и убедитесь, что том хранения с этими определениями доступен.

Use of hostPort (использование хост-порта):Если вы подключаете pods к хост-порту, вы можете быть ограничены планированием только одного pod на узел. В большинстве случаев вы можете пропустить использование HostPort и вместо этого использовать объект Service для связи с вашим pod.

## Удаление OOM из-за достижения лимита контейнера

Это, безусловно, самая основная проблема с памятью, которая может возникнуть в pod. Вы указываете ограничение памяти, и один контейнер пытается выделить больше памяти, чем разрешено, что приводит к ошибке. Обычно это приводит к тому, что контейнер умирает, один модуль становится неработоспособным, и Kubernetes перезапускает этот pod.

Вывод описания pod будет выглядеть примерно так:


Код выхода 137 важен, поскольку он указывает, что контейнер был закрыт системой, поскольку он пытался использовать больше памяти, чем его предел.

###  Поиск неисправностей:

Если под был закрыт из-за ограничения контейнера, то:

- Определите, действительно ли вашей программе нужна дополнительная память. Например, если программа представляет собой веб-сайт с повышенным трафиком, ей может потребоваться больше памяти, чем было первоначально запрошено. Чтобы решить проблему в этом сценарии, увеличьте ограничение оперативной памяти для контейнера в спецификации модуля.

- Если память неожиданно использует скачки и не связана с загрузкой приложений, возможно, в программе возникла утечка памяти. Отладьте программу и найдите источник утечки памяти. В этом случае не следует увеличивать лимит ОЗУ, поскольку это приведет к тому, что приложение будет потреблять слишком много ресурсов на узлах.

Если под был прекращен из-за превышения лимита узла:
Чрезмерное использование узла возможно, поскольку pods могут планировать на узле, если их память требует значения, минимальное значение памяти меньше, чем память, доступная на узле.

Kubernetes, например, может выполнить 10 контейнеров со значением запроса памяти 1 ГБ на узле с 10 ГБ ОЗУ. Однако если эти контейнеры имеют ограничение памяти в 1,5 ГБ, некоторые модули могут использовать емкость, превышающую минимальную, что приводит к нехватке памяти на узле и принудительному завершению работы некоторых модулей.

Вам необходимо определить, почему Kubernetes решил завершить работу модуля с ошибкой OOMKilled, а также настроить запросы памяти и предельные значения, чтобы гарантировать, что узел не будет перегружен.

Чтобы полностью диагностировать и устранить проблемы с памятью Kubernetes, вы должны отслеживать свою среду, понимать поведение памяти модулей и контейнеров в сравнении с ограничениями и точно настраивать параметры. Без соответствующих инструментов это может оказаться сложной и трудоемкой задачей.

## Troubleshooting Node Not Ready Error

Когда рабочий узел завершает работу или выходит из строя, все модули с состоянием на нем становятся недоступными, а статус узла меняется на NotReady .

Если узел находится в состоянии NotReady более пяти минут (по умолчанию), Kubernetes переключает статус запланированных на нем модулей на Unknown и пытается запланировать его на другом узле со статусом ContainerCreating .

Чтобы определить проблему, выполните следующую команду:
```
kubectl get nodes
```
Проблема будет решена, если неисправный узел сможет восстановиться или будет перезапущен пользователем. Когда вышедший из строя узел восстанавливается и снова присоединяется к кластеру, происходит следующее:

- Под со статусом «Unknown» удаляется, а тома на неисправном узле отключаются.
- Под перепланируется на новый узел, его состояние меняется с Unknown на ContainerCreating, и необходимые тома связываются.
- Kubernetes использует пятиминутную задержку (по умолчанию), после которой модуль начнет работать на узле, и его состояние изменится с ContainerCreating на Running.

Если у вас нет времени ждать или узел не может восстановиться, вам нужно будет помочь Kubernetes перепланировать модули с отслеживанием состояния на другом рабочем узле. Есть два способа сделать это:

- С помощью команды kubectl delete node [имя] удалите неисправный узел из кластера.
- Удалите модули с сохранением состояния с неизвестным статусом — с помощью команды kubectl delete pods [имя_пода] –grace- period=0 –force -n [пространство имен]

## Устранение неполадок кластеров Kubernetes

Первым шагом в диагностике проблем с контейнером является сбор базовой информации о рабочих узлах и службах Kubernetes, активных в кластере.

Запустите kubectl get nodes –show-labels, чтобы получить список рабочих узлов и их статус.

Выполните следующую команду, чтобы получить информацию о службах, которые в данный момент работают в кластере:
```
kubectl cluster-info
```

### Получение журналов кластера:

Чтобы обнаружить более глубокие проблемы с узлами вашего кластера, вам понадобится доступ к журналам узлов. В таблице ниже указано, где найти журналы.

| Тип узла    | Компонент   | Где найти журналы          |
| ----------- | ----------- | ---------------------------|
| Master	  | API Server	| /var/log/kube-apiserver.log|
| Master      | Scheduler   | /var/log/kube-scheduler.log|
| Master      | Controller Manager|/var/log/kube-controller-manager.log|
| Worker      | Kubelet     | /var/log/kubelet.log       |
| Worker      | Kube Proxy  | /var/log/kube-proxy.log    |

Давайте рассмотрим некоторые частые ситуации сбоев кластера, их последствия и способы их решения. Это не исчерпывающее руководство по устранению неполадок кластера, но оно поможет вам решить наиболее распространенные трудности.

Виртуальная машина API-сервера отключается или происходит сбой:

- Влияние: вы не сможете запускать, завершать или обновлять модули и службы, если сервер API недоступен.
- Решение:  Перезапустите виртуальную машину сервера API.
- Предотвращение: установите автоматический перезапуск виртуальной машины сервера API и настройте высокую доступность сервера API.

Control Plane Service отключается или происходит сбой:

- Влияние. Поскольку такие службы, как диспетчер контроллера репликации, планировщик и т. д., расположены рядом с API-сервером, последствия закрытия или сбоя любого из них такие же, как и отключение API-сервера.
- Решение: то же самое, что и при выключении виртуальной машины API-сервера.
- Предотвращение: то же, что и при отключении виртуальной машины API-сервера.

API Server Storage Lost:

- Воздействие. Сервер API не перезагружается после выключения.
- Решение. Убедитесь, что хранилище снова работает, вручную восстановите состояние API-сервера из резервной копии и перезапустите его.
- Предотвращение: убедитесь, что у вас есть готовый снимок сервера API. Используйте надежное хранилище, например Amazon Elastic Block Storage (EBS), которое выдерживает отключение виртуальной машины API-сервера и отдает приоритет хранилищу с высокой доступностью.

Worker Node Shuts Down:

- Воздействие. Если модули узла перестанут работать, планировщик попытается выполнить их на других доступных узлах. Общая способность кластера управлять модулями будет снижена.
- Решение: Определите проблему на узле, перезапустите его и зарегистрируйте в кластере.
- Предотвращение: используйте элемент управления репликацией или службу перед модулями, чтобы гарантировать, что сбои узлов не повлияют на пользователей. Создавайте отказоустойчивые программы.

Kubelet Malfunction:

- Воздействие. Если произойдет сбой kubelet узла, вы не сможете создавать новые модули на этом узле. Существующие модули могут быть удалены, а могут и не быть удалены, а узел будет обозначен как неработоспособный.
- Решение: то же самое, что и при выключении рабочего узла.
- Предотвращение: то же самое, что и при отключении рабочего узла.

## Заключение

Обслуживание кластера Kubernetes — постоянная задача. Несмотря на то, что он призван упростить управление контейнерными приложениями, крайне важно поддерживать и поддерживать работоспособность кластера.
