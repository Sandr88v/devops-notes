---
title: "Wget tips"
date: 2024-03-30T16:43:40+03:00
slug: wget_tips
aliases:
  - wget_tips
weight: 10012
toc_hide: true
tags:
  - linux
---
Wget - это утилита командной строки GNU для загрузки файлов из Интернета с использованием протоколов HTTP, HTTPS, FTP, SFTP. Wget работает и через прокси, и даже в фоновом режиме. Часто используется для скачивания как отдельных файлов, так и целых сайтов.

## Установка Wget
```
sudo yum install -y wget     // CentOS7/RHEL 7/Fedora
sudo dnf install -y wget     // CentOS8/RHEL8/Rocky Linux8
sudo apt install -y wget     // Ubuntu/Debian
sudo pacman -S wget          // Arch Linux
sudo zypper install wget     // OpenSUSE
```

## Синтаксис и опции Wget

Команда wget имеет следующий синтаксис:
```
wget [option] [URL]
```
Опции являются необязательными, но в большинстве случаев они используются для более тонкой настройки параметров загрузки.

Синтаксис опций очень свободный. У каждой опции, как правило есть как длинное, так и короткое имя. Их можно записывать как до URL, так и после. Между опцией и ее значением не обязательно ставить пробел, например вы можете написать -o log или -olog. Эти значения эквивалентны. Также если у опций нет параметров, не обязательно начинать каждую с дефиса, можно записать их все вместе: -drc и -d -r -c. Эти параметры wget тоже эквивалентны.

Основные (список не полный) опции Wget:

`-V (--version) - вывести версию программы `
`-h (--help) - вывести справку`
`-b (--background) - работать в фоновом режиме`
`-d (--debug) - включить режим отладки`
`-v (--verbose) - выводить максимум информации о работе утилиты`
`-q (--quiet) - выводить минимум информации о работе`
`-i файл (--input-file) - прочитать URL из файла`
`--force-html - читать файл указанный в предыдущем параметре как html`
`-t (--tries) - количество попыток подключения к серверу`
`-O файл (--output-document) - файл в который будут сохранены полученные данные`
`-с (--continue) - продолжить ранее прерванную загрузку`
`-S (--server-response) - вывести ответ сервера`
`--spider - проверить работоспособность URL`
`-T время (--timeout) - таймаут подключения к серверу`
`--limit-rate - ограничить скорость загрузки`
`-w (--wait) - интервал между запросами`
`-Q (--quota) - максимальный размер загрузки`
`-4 (--inet4only) - использовать протокол ipv4`
`-6 (--inet6only) - использовать протокол ipv6`
`-U (--user-agent) - строка USER AGENT отправляемая серверу`
`-r (--recursive)- рекурсивная работа утилиты`
`-l (--level) - глубина при рекурсивном сканировании`
`-k (--convert-links) - конвертировать ссылки в локальные при загрузке страниц`
`-P (--directory-prefix) - каталог, в который будут загружаться файлы`
`-m (--mirror) - скачать сайт на локальную машину`
`-p (--page-requisites) - во время загрузки сайта скачивать все необходимые ресурсы`

## Скачать файл
Wget скачает один файл и сохранит его в текущей директории. Во время загрузки мы увидим прогресс, размер файла, дату его последнего изменения, а также скорость загрузки:
`wget http://ftp.gnu.org/gnu/wget/wget2-latest.tar.gz`

## Сохранить файл в специальный каталог

Можно скачать файл и поместить его в другом каталоге, используя опцию -P:

`wget -P ~/Download wget.tar.gz http://ftp.gnu.org/gnu/wget/wget2-latest.tar.gz`

Сохранить файл с другим именем
Опция -О позволяет задать имя сохраняемому файлу, например, скачать файл wget2-latest.tar.gz с именем wget.tar.gz:

`wget -O wget.tar.gz http://ftp.gnu.org/gnu/wget/wget2-latest.tar.gz`

## Скачать несколько файлов
Можно скачать несколько файлов одной командой даже по разным протоколам, просто указав их URL:

`wget http://ftp.gnu.org/gnu/wget/wget2-latest.tar.gz ftp://ftp.gnu.org/gnu/wget/wget2-latest.tar.gz.sig`

В данном примере мы скачали два файла по протоколам HTTP и FTP.

## Взять URL из файла (загрузка из файла)
Можно сохранить несколько URL в файл, а затем загрузить их все, передав файл опции -i. Например создадим файл links.txt, со ссылками для загрузки:

`wget -i ~/Wget/links.txt`

## Продолжить загрузку
Если загружался большой файл, и во время загрузки было потеряно соединение, то можно скачать файл с помощью опции -c:

`wget -c http://ftp.gnu.org/gnu/wget/wget2-latest.tar.gz`

## Загрузка файлов в фоне

Для файлов особо большого размера может оказаться полезной опция -b. Она установит скачивание в фоновом режиме.

`wget -b http://ftp.gnu.org/gnu/wget/wget2-latest.tar.gz`

В каталоге, из которого запускался wget появится wget-log файл, который может быть использован для проверки прогресса и статуса вашего скачивания.

Эта команда тоже будет полезной

`# директория, в которой запускается wget`
`tail -f wget-log`

## Ограничение скорости загрузки

Wget позволяет не только продолжать загрузку файлов, но и ограничивать скорость загрузки. Для этого есть опция --limit-rate.

Это полезно, когда необходимо скачать большой файл. Мы предотвращаем полное использования канала. Например, ограничим скорость загрузки до 500 килобит + установим флаг для фонового скачивания:

`wget --limit-rate=500k -b https://cdimage.debian.org/debian-cd/current/amd64/iso-cd/debian-11.6.0-amd64-netinst.iso`

## Количество повторных попыток

Проблемы подключения к интернету могут привести к прерыванию загрузки. Чтобы этого избежать можно повысить количество повторных попыток с опцией -tries:

`wget -tries http://ftp.gnu.org/gnu/wget/wget2-latest.tar.gz`


## Подключение по логину и паролю

Некоторые ресурсы требуют аутентификации, для загрузки их файлов. С помощью опций --http-user=username, --http-password=password и --ftp-user=username, --ftp-password=password можно задать имя пользователя и пароль для HTTP или FTP ресурсов.

`wget --ftp-user=YOUR_USERNAME --ftp-password=YOUR_PASSWORD ftp://example.com/something.tar`

## Квота загрузки
Если доступно только ограниченное количество трафика, можно указать какое количество информации можно скачивать, например разрешим скачать файлов из списка только на десять мегабайт:

`wget -Q 10m -i ~/Wget/links.txt`

## Загрузить и выполнить

Можно сразу же выполнять скачанные скрипты:

`wget -O - https://site.com/script.sh | bash`

Если опции -O не передать аргументов, то скачанный файл будет выведен в стандартный вывод, затем мы его можем перенаправить с интерпретатор bash, как показано выше.

## Поиск битых ссылок

`wget -o wget-log -r -l 5 --spider https://site.com`

Теперь мы можем изучить файл wget-log для поиска списка битых ссылок. Вот команда для этого:

`grep -B 2 '404' wget-log | grep "http" | cut -d " " -f 4 | sort -u`

## Скачать пронумерованный файлы

Если есть список файлов или изображений пронумерованные в определённом порядке, можно легко скачать их все, используя следующий синтаксис:

`wget https://site.com/images/{1..50}.jpg`

## Скачать сайт

Wget позволяет скачивать не только одиночные файлы, но и целые сайты, чтобы вы могли их потом просматривать в офлайне. Скачивается html версия сайта со всеми стилями и картинками:

`# Самый простой способ (одностраничный сайт)`
`wget --mirror https://site.com`

`# более объёмный сайт с уровнем рекурсии в 10`
`wget -mrkcb -l 10 -P ~/Download https://site.com`

Ещё по теме
[Linux wget1](https://man7.org/linux/man-pages/man1/wget.1.html)
[Linux wget2](https://www.gnu.org/software/wget/manual/wget.html)










